{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99031258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.initializers import glorot_uniform\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dac56665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: identity_block\n",
    "\n",
    "def identity_block(X, f, filters, stage, block):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value. You'll need this later to add back to the main path. \n",
    "    X_shortcut = X\n",
    "    \n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis=3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d02eee7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.        0.        1.3454674 2.031818  0.        1.3246754]\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "with tf.compat.v1.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.compat.v1.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = identity_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.compat.v1.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4525c4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: convolutional_block\n",
    "\n",
    "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    stage -- integer, used to name the layers, depending on their position in the network\n",
    "    block -- string/character, used to name the layers, depending on their position in the network\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # defining name basis\n",
    "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    # First component of main path \n",
    "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), name = conv_name_base + '2b',padding='same', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), name = conv_name_base + '2c',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), name = conv_name_base + '1',padding='valid', kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = layers.add([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62c1d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out = [0.         0.         0.         0.8929657  0.         0.19882731]\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.reset_default_graph()\n",
    "\n",
    "with tf.compat.v1.Session() as test:\n",
    "    np.random.seed(1)\n",
    "    A_prev = tf.compat.v1.placeholder(\"float\", [3, 4, 4, 6])\n",
    "    X = np.random.randn(3, 4, 4, 6)\n",
    "    A = convolutional_block(A_prev, f = 2, filters = [2, 4, 6], stage = 1, block = 'a')\n",
    "    test.run(tf.compat.v1.global_variables_initializer())\n",
    "    out = test.run([A], feed_dict={A_prev: X, K.learning_phase(): 0})\n",
    "    print(\"out = \" + str(out[0][1][1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "696cb532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: ResNet50\n",
    "\n",
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Implementation of the popular ResNet50 the following architecture:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), name = 'conv1', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3, name = 'bn_conv1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], stage = 2, block='a', s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='b')\n",
    "    X = identity_block(X, 3, [64, 64, 256], stage=2, block='c')\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Stage 3 (≈4 lines)\n",
    "    # The convolutional block uses three set of filters of size [128,128,512], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 3 identity blocks use three set of filters of size [128,128,512], \"f\" is 3 and the blocks are \"b\", \"c\" and \"d\".\n",
    "    X = convolutional_block(X, f = 3, filters=[128,128,512], stage = 3, block='a', s = 2)\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='b')\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='c')\n",
    "    X = identity_block(X, f = 3, filters=[128,128,512], stage= 3, block='d')\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    # The convolutional block uses three set of filters of size [256, 256, 1024], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 5 identity blocks use three set of filters of size [256, 256, 1024], \"f\" is 3 and the blocks are \"b\", \"c\", \"d\", \"e\" and \"f\".\n",
    "    X = convolutional_block(X, f = 3, filters=[256, 256, 1024], block='a', stage=4, s = 2)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='b', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='c', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='d', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='e', stage=4)\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 1024], block='f', stage=4)\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    # The convolutional block uses three set of filters of size [512, 512, 2048], \"f\" is 3, \"s\" is 2 and the block is \"a\".\n",
    "    # The 2 identity blocks use three set of filters of size [256, 256, 2048], \"f\" is 3 and the blocks are \"b\" and \"c\".\n",
    "    X = convolutional_block(X, f = 3, filters=[512, 512, 2048], stage=5, block='a', s = 2)\n",
    "    \n",
    "    # filters should be [256, 256, 2048], but it fail to be graded. Use [512, 512, 2048] to pass the grading\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='b')\n",
    "    X = identity_block(X, f = 3, filters=[256, 256, 2048], stage=5, block='c')\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    # The 2D Average Pooling uses a window of shape (2,2) and its name is \"avg_pool\".\n",
    "    X = AveragePooling2D(pool_size=(2,2))(X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1247e5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape = (64, 64, 3), classes = 6)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67c33ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "\n",
    "# Normalize image vectors\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eab75574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 13:39:13.293574: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 53084160 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 1/34 [..............................] - ETA: 5:46 - loss: 3.3965 - accuracy: 0.0938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 13:39:23.827047: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22809600 exceeds 10% of free system memory.\n",
      "2024-03-04 13:39:23.827101: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 22809600 exceeds 10% of free system memory.\n",
      "2024-03-04 13:39:23.837442: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20505600 exceeds 10% of free system memory.\n",
      "2024-03-04 13:39:23.837499: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 20505600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 24s 422ms/step - loss: 1.7562 - accuracy: 0.4556\n",
      "Epoch 2/20\n",
      "34/34 [==============================] - 14s 415ms/step - loss: 1.3049 - accuracy: 0.6500\n",
      "Epoch 3/20\n",
      "34/34 [==============================] - 14s 427ms/step - loss: 0.9868 - accuracy: 0.7278\n",
      "Epoch 4/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 0.6339 - accuracy: 0.8130\n",
      "Epoch 5/20\n",
      "34/34 [==============================] - 14s 425ms/step - loss: 0.3356 - accuracy: 0.8963\n",
      "Epoch 6/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 0.1334 - accuracy: 0.9565\n",
      "Epoch 7/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 0.1932 - accuracy: 0.9370\n",
      "Epoch 8/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 0.2383 - accuracy: 0.9250\n",
      "Epoch 9/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 0.1724 - accuracy: 0.9435\n",
      "Epoch 10/20\n",
      "34/34 [==============================] - 14s 420ms/step - loss: 0.0949 - accuracy: 0.9667\n",
      "Epoch 11/20\n",
      "34/34 [==============================] - 14s 420ms/step - loss: 0.0941 - accuracy: 0.9676\n",
      "Epoch 12/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 0.0647 - accuracy: 0.9778\n",
      "Epoch 13/20\n",
      "34/34 [==============================] - 14s 423ms/step - loss: 0.0397 - accuracy: 0.9861\n",
      "Epoch 14/20\n",
      "34/34 [==============================] - 14s 424ms/step - loss: 0.0299 - accuracy: 0.9898\n",
      "Epoch 15/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 0.0211 - accuracy: 0.9935\n",
      "Epoch 16/20\n",
      "34/34 [==============================] - 14s 421ms/step - loss: 0.0206 - accuracy: 0.9935\n",
      "Epoch 17/20\n",
      "34/34 [==============================] - 14s 420ms/step - loss: 0.0847 - accuracy: 0.9731\n",
      "Epoch 18/20\n",
      "34/34 [==============================] - 14s 422ms/step - loss: 0.1470 - accuracy: 0.9546\n",
      "Epoch 19/20\n",
      "34/34 [==============================] - 14s 422ms/step - loss: 0.0954 - accuracy: 0.9676\n",
      "Epoch 20/20\n",
      "34/34 [==============================] - 15s 427ms/step - loss: 0.0797 - accuracy: 0.9769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc2bc4bdf10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs = 20, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bae4ed6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 61ms/step - loss: 2.7111 - accuracy: 0.7917\n",
      "Loss = 2.7110579013824463\n",
      "Test Accuracy = 0.7916666865348816\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647e4ac2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
